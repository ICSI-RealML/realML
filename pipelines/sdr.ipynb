{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be updated for new SDR interface\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.io.matlab import loadmat\n",
    "#import sktensor\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "#from sktensor.rescal import als as rescal_als\n",
    "from numpy import zeros, dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import precision_recall_curve, auc, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import normalize\n",
    "import os, json\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import OrderedDict\n",
    "from realML.matrix import SDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkPrediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def tensorCompletion(T, V=[]):\n",
    "    \"\"\"\n",
    "    Complete the tensor by tensor factorization and recomposition (we use Rescal)\n",
    "    \"\"\"\n",
    "    def __predict_rescal_als(T, V=[]):\n",
    "        if V==[]:\n",
    "            A, R, _, _, _ = rescal_als(T, 100, init='nvecs', conv=1e-3, lambda_A=10, lambda_R=10)\n",
    "        else:\n",
    "            A, R, _, _, _ = rescal_als(T, 100, attr=[V], init='nvecs', conv=1e-3, lambda_A=10, lambda_R=10)\n",
    "        n = A.shape[0]\n",
    "        P = zeros((n, n, len(R)))\n",
    "        for k in range(len(R)):\n",
    "            P[:, :, k] = dot(A, dot(R[k], A.T))\n",
    "        return P\n",
    "    def __normalize_predictions(P, e, k):\n",
    "        for a in range(e):\n",
    "            for b in range(e):\n",
    "                nrm = norm(P[a, b, :k])\n",
    "                if nrm != 0:\n",
    "                    # round values for faster computation of AUC-PR\n",
    "                    P[a, b, :k] = np.round_(P[a, b, :k] / nrm, decimals=3)\n",
    "        return P\n",
    "\n",
    "    e, k = T.shape[0], T.shape[2]\n",
    "\n",
    "    # Convert T into list of sparse matrices as required by Rescal\n",
    "    T = [lil_matrix(T[:, :, i]) for i in range(k)]\n",
    "    Tc = [Ti.copy() for Ti in T]\n",
    "\n",
    "    # call Rescal and normalize\n",
    "    P = __predict_rescal_als(Tc, V)\n",
    "    P = __normalize_predictions(P, e, k)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorCompletion:\n",
    "    def __init__(self, T):\n",
    "        self.T = T\n",
    "        self.P = np.zeros_like(T)\n",
    "        for k in range(T.shape[2]):\n",
    "            sdrObj = SDR(dim=10, numrandfeats=1000)\n",
    "            sdrObj.set_training_data(inputs=[np.squeeze(T[:,:,k])])\n",
    "            sdrObj.fit(iterations=10)\n",
    "            U, V = sdrObj.produce()\n",
    "            self.P[:, :, k] = np.exp(U.dot(V.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class LinkPrediction():\n",
    "    def __init__(self, G):\n",
    "        \"\"\"\n",
    "        G is an instance of nx.MultiGraph\n",
    "        \"\"\"\n",
    "        # convert the graph into adjacency tensor\n",
    "        I = len(G.nodes())\n",
    "        J = I\n",
    "        K = len(set(nx.get_edge_attributes(G,'linkType').values()))\n",
    "        shape = (I, J, K)\n",
    "        print(shape)\n",
    "        self.A = np.zeros(shape=shape)\n",
    "        for i,j,data in G.edges(data=True):\n",
    "            k = (data['linkType'])\n",
    "            self.A[i][j][k] = 1.\n",
    "        print(self.A.shape)\n",
    "    \n",
    "    def fit(self):\n",
    "        # self.A_completed = tensorCompletion(self.A, attrDF.as_matrix())\n",
    "        self.A_completed = tensorCompletion(self.A).P\n",
    "        print(np.amin(self.A_completed))\n",
    "        print(np.amax(self.A_completed))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X is a DataFrame with columns=[source_nodeID, target_nodeID, linkType]\n",
    "        \"\"\"\n",
    "        def __predictLink(row, T):\n",
    "            k = int(row.linkType)\n",
    "            i = int(row.source_nodeID)\n",
    "            j = int(row.target_nodeID)\n",
    "            return int(round(T[i][j][k]))\n",
    "        X['linkExists']=X.apply(__predictLink, T=self.A_completed, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializations\n",
    "dataDir = \"./r_59/data\"\n",
    "rawDataDir = os.path.join(dataDir, \"raw_data\")\n",
    "assert os.path.exists(dataDir)\n",
    "assert os.path.exists(rawDataDir)\n",
    "\n",
    "random.seed(50)\n",
    "\n",
    "graph = '%s/graph.gml'%rawDataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read graph ...\n",
      "setting aside 10% of edges for validation and remove them from graph ....\n",
      "number of edge set aside for validation: 431\n"
     ]
    }
   ],
   "source": [
    "# read the graph from gml file\n",
    "print('read graph ...')\n",
    "G = nx.read_gml(graph, label='id')\n",
    "    \n",
    "# set aside some edges (10%) validation of the model\n",
    "print('setting aside 10% of edges for validation and remove them from graph ....')\n",
    "edges_validation=pd.DataFrame(columns=['source_nodeID','target_nodeID','linkType'])\n",
    "for i, (u,v,key,data) in enumerate(G.edges(data=True, keys=True)):\n",
    "    if random.random() < 0.1:\n",
    "        G.remove_edge(u,v,key=key)\n",
    "        edges_validation.loc[len(edges_validation)] = [u,v,data['linkType']]\n",
    "print('number of edge set aside for validation:',len(edges_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing the linkPrediction model ...\n",
      "(135, 135, 49)\n",
      "(135, 135, 49)\n",
      "fitting the training graph ...\n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      "0.1.2.3.4.5.6.7.8.9. \n",
      "0.00966501691548\n",
      "652.565187613\n",
      "making predictions on validation edges ...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print('initializing the linkPrediction model ...')\n",
    "lp = LinkPrediction(G)\n",
    "\n",
    "# fit the training graph\n",
    "print('fitting the training graph ...')\n",
    "lp.fit()\n",
    "\n",
    "# make predictions on the validation data\n",
    "print('making predictions on validation edges ...')\n",
    "edges_prediction=lp.predict(edges_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing accuracy on validation data ...\n",
      "model accuracy: 0.14153132250580047\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on validation data\n",
    "print('computing accuracy on validation data ...')\n",
    "accuracy = len(edges_prediction[edges_prediction['linkExists']==1])/len(edges_prediction)\n",
    "print('model accuracy:', accuracy)\n",
    "train_performance = OrderedDict([\n",
    "    ('train', OrderedDict([\n",
    "        ('split', OrderedDict([\n",
    "                ('type', 'custom'),\n",
    "                ('n_splits', 1),\n",
    "                ('shuffle', True),\n",
    "                ('test_size', 0.1)])\n",
    "        ),\n",
    "        ('score', OrderedDict([\n",
    "                ('metric', 'accuracy'),\n",
    "                ('value', accuracy)])\n",
    "        )\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model on the whole graph ...\n",
      "(135, 135, 49)\n",
      "(135, 135, 49)\n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "Constructing PPMI\n",
      "0.0.Refining\n",
      " \n",
      "0.556685912396\n",
      "2.71828182846\n"
     ]
    }
   ],
   "source": [
    "# now train the model on the whole graph\n",
    "print('training the model on the whole graph ...')\n",
    "# read the graph from gml file\n",
    "G = nx.read_gml(graph, label='id')\n",
    "# initialize the model\n",
    "lp = LinkPrediction(G)\n",
    "# fit the graph\n",
    "lp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3977"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predictions on test data ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('read the testData ...')\n",
    "    testData = pd.read_csv('%s/testData.csv'%dataDir, index_col=0)\n",
    "    print(testData['source_nodeID'].min())\n",
    "    print(testData['source_nodeID'].max())\n",
    "    print(testData['target_nodeID'].min())\n",
    "    print(testData['target_nodeID'].max())\n",
    "    \n",
    "    print('make prediciton on testData and save as testTargets.csv')\n",
    "    predictions = lp.predict(testData)\n",
    "    y_predicted = pd.DataFrame(predictions['linkExists'])\n",
    "    y_predicted.to_csv('testTargets.csv')\n",
    "except:\n",
    "    print('Looks like this is a redacted dataset. testData is unavailable. Cannot complete this step ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediciton on testData and save the testTargets.cav\n",
    "predictions = lp.predict(testData)\n",
    "y_predicted = pd.DataFrame(predictions['linkExists'])\n",
    "y_predicted.to_csv('testTargets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('read predicted values ....')\n",
    "    y_predicted = pd.read_csv('testTargets.csv')['linkExists']\n",
    "    \n",
    "    print('read truth values ...')\n",
    "    y_truth = pd.read_csv('%s/testTargets.csv'%dataDir)['linkExists']\n",
    "    \n",
    "    print('computing performance ...')\n",
    "    accuracy = [\n",
    "        accuracy_score(y_truth, y_predicted), # accuracy of the current model\n",
    "        accuracy_score(y_truth, np.zeros(len(y_truth))), # accuracy if you guessed 0 for all links\n",
    "        accuracy_score(y_truth, np.ones(len(y_truth))), # accuracy if you guessed 1 for all links\n",
    "        accuracy_score(y_truth, np.random.choice([0, 1], size=(len(y_truth),))),] # accuracy if you randomly guessed 0 or 1\n",
    "    print('accuracy',accuracy[0])\n",
    "    test_performance = OrderedDict([\n",
    "        ('test', OrderedDict([\n",
    "            ('score', OrderedDict([\n",
    "                    ('metric', 'accuracy'),\n",
    "                    ('value', accuracy[0])])\n",
    "            )\n",
    "        ]))\n",
    "    ])\n",
    "except:\n",
    "    print('Looks like this is a redacted dataset. testTargets is unavailable. cannot complete this step ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_performance = OrderedDict()\n",
    "overall_performance.update(train_performance)\n",
    "overall_performance.update(test_performance)\n",
    "\n",
    "with open('performance.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(overall_performance, f, indent=2)\n",
    "print(json.dumps(overall_performance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
